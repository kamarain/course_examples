{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of regression with a neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages for sine wave generation and plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First we need to generate training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a sine wave\n",
    "t = np.arange(0, 10, 0.1);\n",
    "y = np.sin(t)\n",
    "plot.plot(t, y)\n",
    "plot.title('Training data for regression y=f(t)')\n",
    "plot.xlabel('Time')\n",
    "plot.ylabel('y = sin(t)')\n",
    "plot.grid(True, which='both')\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary packages for neural networks\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the structure sequential we can add layers one by one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model sequential\n",
    "model = Sequential()\n",
    "# First hidden layer (we also need to tell the input dimension)\n",
    "model.add(Dense(10, input_dim=1, activation='sigmoid'))\n",
    "# First hidden layer (we also need to tell the input dimension)\n",
    "model.add(Dense(10, activation='sigmoid'))\n",
    "# Output layer\n",
    "#model.add(Dense(1, activation='sigmoid'))\n",
    "model.add(Dense(1, activation='tanh'))\n",
    "model.compile(optimizer='sgd', loss='mse', metrics=['mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we ready to train the network with our input output pairs (t,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(t, y, epochs=5000, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now we can test the prediction power of the network and compare to training data (i.e. how well it fits to the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error \n",
    "y_pred = model.predict(t)\n",
    "print(y[1])\n",
    "print(y_pred[1])\n",
    "print(np.sum(np.absolute(np.subtract(y,y_pred)))/len(t))\n",
    "print(np.square(np.subtract(y,y_pred)).mean())\n",
    "print(len(y))\n",
    "print(np.divide(np.sum(np.square(y-y_pred)),len(y)))\n",
    "print('MSE=',mean_squared_error(y,y_pred))\n",
    "plot.plot(t, y, label='y')\n",
    "plot.plot(t, y_pred, label='y_pred')\n",
    "plot.title('Training data (sive wave)')\n",
    "plot.xlabel('Time')\n",
    "plot.ylabel('y = sin(t)')\n",
    "plot.grid(True, which='both')\n",
    "plot.legend()\n",
    "plot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
